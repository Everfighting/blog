---
title: AI日报 2026-02-14
date: 2026-02-14 23:59:59
tags:
  - AI日报
  - AI知识点
  - 论文推荐

categories: AI日报
description: 每日AI知识点推送与论文推荐汇总
abbrlink: ai-daily-20260214
toc: true
---

## 📚 今日知识点

1. 【项目经验】AI产品MVP验证：先不做完整功能，用GPT-4 API+简单前端快速验证需求。真实用户反馈比预判重要10倍。

2. 【项目经验】成本优化：小模型+Prompt工程 > 大模型+暴力Prompt。7B模型调优后，很多任务能达到GPT-4的80%效果，成本只有1/10。

3. 【LLM】上下文窗口是记忆容量：GPT-4是128K，Claude是200K。长对话中可以用滑动窗口或RAG技术避免遗忘关键信息。

4. 【Vibe Coding】相信AI但验证结果：让AI写复杂逻辑，但你必须理解代码结构。不理解的东西，永远不要直接部署到生产环境。

5. 【LLM】Temperature参数控制输出的随机性：0.1=确定性高（适合代码、文档），0.7=平衡（适合创意写作），1.0+=创造性强但可能不连贯。

6. 【项目经验】成本优化：小模型+Prompt工程 > 大模型+暴力Prompt。7B模型调优后，很多任务能达到GPT-4的80%效果，成本只有1/10。

7. 【项目经验】成本优化：小模型+Prompt工程 > 大模型+暴力Prompt。7B模型调优后，很多任务能达到GPT-4的80%效果，成本只有1/10。

8. 【架构】LangChain vs LangGraph：Chain是线性流程，Graph是循环流程。复杂Agent用LangGraph，简单任务用LangChain足够。

9. 【Agent】Self-Reflection让Agent自我修正：在每步行动后，让模型评估结果并调整策略。显著提升复杂任务的成功率。

10. 【LLM】Few-shot learning比Zero-shot效果更好：给2-3个示例，模型理解能力显著提升。示例格式很重要，保持一致性。

11. 【项目经验】AI产品MVP验证：先不做完整功能，用GPT-4 API+简单前端快速验证需求。真实用户反馈比预判重要10倍。

12. 【项目经验】监控AI系统：除了延迟和成功率，还要监控「幻觉率」和「拒答率」。这些指标直接影响用户体验。

13. 【LLM】上下文窗口是记忆容量：GPT-4是128K，Claude是200K。长对话中可以用滑动窗口或RAG技术避免遗忘关键信息。

14. 【LLM】Temperature参数控制输出的随机性：0.1=确定性高（适合代码、文档），0.7=平衡（适合创意写作），1.0+=创造性强但可能不连贯。

15. 【Agent】ReAct模式：Reasoning（思考）+ Acting（行动）。Agent先分解任务，再逐步执行，最后验证结果。是复杂任务的标准范式。


## 📖 论文推荐

1. **Self-Refine (2024)**
   - 作者: Various Researchers
   - 简介: 生成-批评-改进循环。比一次性生成质量更高，代码、写作必备。

2. **Attention Is All You Need (2017)**
   - 作者: Vaswani et al. (Google Brain)
   - 简介: 引用10万+！Transformer论文，彻底改变NLP领域。自注意力机制是所有大模型（GPT、BERT、Claude）的架构基础。必读经典。

3. **Mixture of Agents (2024)**
   - 作者: Together AI
   - 简介: 多Agent协作框架，每个专注一领域。通过aggregation得到更好结果。

4. **Tree of Thoughts (2023)**
   - 作者: Yao et al.
   - 简介: 引用1500+！思维树方法，探索多个推理路径并回溯。数学、编程等复杂任务效果显著。

5. **BERT: Pre-training of Deep Bidirectional Transformers (2019)**
   - 作者: Devlin et al. (Google)
   - 简介: 引用8万+！首次证明双向预训练的效果。BERT刷新11项NLP任务SOTA，开启了预训练语言模型时代。

6. **GraphRAG (2024)**
   - 作者: Microsoft Research
   - 简介: 结合知识图谱+社区检测，解决RAG全局性盲点。企业级知识库必备技术。

7. **Toolformer (2023)**
   - 作者: Schick et al.
   - 简介: 引用1000+！让模型学习调用外部工具。现代AI工具调用的基础，Agent能力扩展的关键。

8. **Constitutional AI (2022)**
   - 作者: Anthropic
   - 简介: 引用2000+！宪法AI，通过自我批评避免有害输出。Claude模型的核心安全机制，RLHF的替代方案。

9. **Qwen2.5 (2024)**
   - 作者: Alibaba
   - 简介: 72B开源，性能超越闭源模型。数学、编程、长文本突出。中国开源AI的重要里程碑。

10. **Chain of Density (2024)**
   - 作者: Various Researchers
   - 简介: 迭代增加摘要密度，简洁且信息丰富。长文档摘要必备。

11. **Instruction Tuning (2022)**
   - 作者: Wei et al. (Google)
   - 简介: 引用5000+！证明指令微调让单一模型完成多任务。ChatGPT等聊天机器人的技术基础。

12. **DeepSeek-V3: Technical Report (2025)**
   - 作者: DeepSeek Team
   - 简介: 开源MoE架构，671B参数激活仅37B。性能媲美GPT-4，训练成本560万美元。开源的里程碑。

13. **Language Models are Few-Shot Learners (2020)**
   - 作者: Brown et al. (OpenAI)
   - 简介: 引用6万+！GPT-3论文，定义few-shot learning。175B参数展示规模化效果，是现代prompt技术的起点。

14. **Chain of Density (2024)**
   - 作者: Various Researchers
   - 简介: 迭代增加摘要密度，简洁且信息丰富。长文档摘要必备。

15. **Long Context Beyond 1M Tokens (2024)**
   - 作者: Google, Anthropic
   - 简介: Gemini 1.5、Claude 3突破1M上下文。长文档、代码库、视频内容处理成为可能。

***

*本日报由AI助手自动生成，帮您快速了解AI领域最新动态。*
